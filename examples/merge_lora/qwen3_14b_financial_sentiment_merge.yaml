### 合并 LoRA 权重到基础模型
model_name_or_path: /home/user150/models/Qwen3-14B
adapter_name_or_path: /home/user150/LLaMA-Factory/saves/qwen3-14b/qlora/financial_sentiment/checkpoint-2000
template: qwen3_nothink
finetuning_type: lora

# 如果使用 QLoRA 训练的，需要加上量化配置
quantization_bit: 4
quantization_method: bitsandbytes

# 导出配置
export_dir: /home/user150/models/Qwen3-14B-Financial-Sentiment-Merged
export_size: 5  # 每个分片最大 5GB
export_device: cpu  # 在 CPU 上合并，避免显存不足
export_legacy_format: false  # 使用 safetensors 格式
